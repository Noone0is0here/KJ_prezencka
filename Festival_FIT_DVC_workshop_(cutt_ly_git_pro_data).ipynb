{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Festival@FIT DVC workshop (cutt.ly/git-pro-data)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noone0is0here/KJ_prezencka/blob/main/Festival_FIT_DVC_workshop_(cutt_ly_git_pro_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab for DVC workshop\n",
        "\n",
        "Implements a very basic pipeline that can be changed and present the dvc pipeline features. \n",
        "\n",
        " - Make your own copy `File -> Save a copy in drive` and use that \n",
        " - Initally, just hit `Runtime -> Run all`. \n",
        " - You can then play with the written files - just change the cell for the file and run the cell. It will override the file in storage.\n",
        " - You can also add scratch code cell (`Insert -> Scratch code cell`) where you can run the commands (shell commands start with `!`).\n"
      ],
      "metadata": {
        "id": "2fIG6DUQsXe8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvhf36uZ8KiC",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Python dependencies installation\n",
        "# @markdown Installs dependencies and it will mention that you should restart the runtime.\n",
        "# @markdown You can restart it; however, it is not necessary.\n",
        "! pip install dvc pytorch-lightning typer torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize git and dvc repositories.\n",
        "\n",
        "! git init\n",
        "! git config --global user.email \"you@example.com\"\n",
        "! git config --global user.name \"Your Name\"\n",
        "! dvc init\n",
        "! git add .dvc\n",
        "! git commit -m \"Initial DVC setup\""
      ],
      "metadata": {
        "id": "23y5_05y8N1o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title data_prep.py\n",
        "# @markdown File contains data conversion and preparation for training or testing.\n",
        "\n",
        "%%writefile data_prep.py\n",
        "\n",
        "import pandas as pd\n",
        "import typer\n",
        "import numpy as np\n",
        "import pickle\n",
        "from typing import Optional\n",
        "from scipy.ndimage import rotate\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_rotated_images(images, original_labels, max_angle) -> np.ndarray:\n",
        "  rotated = []\n",
        "  labels = []\n",
        "  for image, label in tqdm(zip(images, original_labels)):\n",
        "    for angle in range(-max_angle, max_angle+1, 10):\n",
        "      rotated.append(rotate(image, angle, reshape=False))\n",
        "      labels.append(label)\n",
        "  return np.stack(rotated), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "def prepare_data(\n",
        "    input_path: str, \n",
        "    output_path: str, \n",
        "    rotate_max_angle: Optional[int] = typer.Option(None),\n",
        "    ):\n",
        "  headers_pixels = [f\"pix{i}\" for i in range(28*28)]\n",
        "  headers = [\"label\"] + headers_pixels\n",
        "  data = pd.read_csv(input_path, header=None, names=headers)\n",
        "  images = np.stack([data[c] for c in headers_pixels])\n",
        "  images = images.T.reshape(-1, 28, 28).astype(np.uint8)\n",
        "  labels = np.array(data.label)\n",
        "  if rotate_max_angle is not None:\n",
        "    images, labels = generate_rotated_images(images, labels, rotate_max_angle)\n",
        "  print(images.shape)\n",
        "  data = {\"labels\": labels, \"images\": images}\n",
        "  with open(output_path, \"wb\") as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  typer.run(prepare_data)\n"
      ],
      "metadata": {
        "id": "Gx3ihV-78aOV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model.py\n",
        "# @markdown Just a helper file with model and some dataset loading.\n",
        "%%writefile model.py\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchmetrics.classification.accuracy import Accuracy\n",
        "import pytorch_lightning as pl\n",
        "import pickle\n",
        "\n",
        "def get_dataset(path):\n",
        "  with open(path, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "  return torch.utils.data.TensorDataset(torch.tensor(data[\"images\"]), torch.tensor(data[\"labels\"]))\n",
        "\n",
        "\n",
        "def _init_weights(m: nn.Module):\n",
        "    \"\"\"Initialize weight of all linear and convolution layers.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "        m (nn.Module): each module of NN\n",
        "    \"\"\"\n",
        "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "        nn.init.normal_(m.weight, std=0.01)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.c1 = nn.Conv2d(1, 6, kernel_size=5, padding=\"same\")\n",
        "        self.pool = nn.MaxPool2d((2,2))\n",
        "        self.c2 = nn.Conv2d(6, 12, kernel_size=5, padding=\"same\")\n",
        "        self.c3 = nn.Conv2d(12, 24, kernel_size=5, padding=\"same\")\n",
        "        \n",
        "        self.feature_vec = nn.Linear(216, 64)\n",
        "        self.final_cls = nn.Linear(64, 10)\n",
        "\n",
        "        self.apply(_init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.c1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.c2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.c3(x)))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.leaky_relu(self.feature_vec(x))\n",
        "        x = F.softmax(self.final_cls(x),dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LitModel(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = Net()\n",
        "    # loss function\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # use separate metric instance for train, val and test step\n",
        "    # to ensure a proper reduction over the epoch\n",
        "    self.accuracies = {phase: Accuracy() for phase in (\"train\", \"val\", \"test\")}\n",
        "    \n",
        "\n",
        "  def forward(self, image):\n",
        "    image = torch.unsqueeze(image, dim=1)\n",
        "    image = image.float() / 255\n",
        "    return self.net(image)\n",
        "    \n",
        "\n",
        "  def _step(self, batch, phase):\n",
        "    x, y = batch\n",
        "    logits = self.forward(x)\n",
        "    loss = self.criterion(logits, y)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    acc_metric = self.accuracies[phase]\n",
        "    acc = acc_metric(preds, y)\n",
        "    self.log(f\"{phase}/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "    return {\"loss\": loss, \"preds\": preds, \"targets\": y}\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    return self._step(batch, \"train\")\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    return self._step(batch, \"val\")\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    return self._step(batch, \"test\")\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    for acc in self.accuracies.values():\n",
        "      acc.reset()\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=0.00005) \n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "CS5sK7wbJn61",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train.py\n",
        "# @markdown Runs training and saves the trained model to model.ckpt\n",
        "\n",
        "%%writefile train.py\n",
        "\n",
        "import typer\n",
        "import torch \n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from model import LitModel, get_dataset\n",
        "\n",
        "def train(max_epochs: int = typer.Option(10), \n",
        "          seed: int = typer.Option(123)):\n",
        "  pl.seed_everything(seed)\n",
        "  \n",
        "  ds = get_dataset(\"sample_data/mnist_train_small.pkl\")\n",
        "  train_images_num = int(0.95*len(ds))\n",
        "  train_ds, val_ds = torch.utils.data.random_split(ds, [train_images_num, len(ds)-train_images_num], generator=torch.Generator().manual_seed(42))\n",
        "  train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "  val_loader = torch.utils.data.DataLoader(val_ds, batch_size=128, shuffle=False)\n",
        "  \n",
        "  trainer = pl.Trainer(max_epochs=max_epochs)\n",
        "  model = LitModel()\n",
        "  trainer.fit(model, train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "  trainer.save_checkpoint(\"model.ckpt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  typer.run(train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Fz4YXW-FKVJX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test.py\n",
        "# @markdown Evaluates the trained model on test data.\n",
        "\n",
        "%%writefile test.py\n",
        "\n",
        "import typer\n",
        "import torch \n",
        "import pytorch_lightning as pl\n",
        "import json\n",
        "\n",
        "from model import LitModel, get_dataset\n",
        "\n",
        "def test():\n",
        "  model = LitModel.load_from_checkpoint(\"model.ckpt\")\n",
        "  ds = get_dataset(\"sample_data/mnist_test.pkl\")\n",
        "  loader = torch.utils.data.DataLoader(ds, batch_size=128, shuffle=False)\n",
        "  \n",
        "  trainer = pl.Trainer()\n",
        "  results = trainer.test(model, loader)\n",
        "  results = results[0]\n",
        "  \n",
        "  with open(\"metrics.json\", \"wt\") as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  typer.run(test)\n"
      ],
      "metadata": {
        "id": "qeU_ktWCM-Nd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title dvc.yaml\n",
        "\n",
        "%%writefile dvc.yaml\n",
        "\n",
        "stages:\n",
        "  prepare_data:\n",
        "    foreach:\n",
        "      train: \n",
        "        input_path: sample_data/mnist_train_small.csv\n",
        "        output_path: sample_data/mnist_train_small.pkl\n",
        "        additional_args: \"\"\n",
        "      test:\n",
        "        input_path: sample_data/mnist_test.csv\n",
        "        output_path: sample_data/mnist_test.pkl\n",
        "        additional_args: \"\"\n",
        "    do:\n",
        "      cmd: python data_prep.py ${item.input_path} ${item.output_path} ${item.additional_args}\n",
        "      deps:\n",
        "        - ${item.input_path}\n",
        "        - data_prep.py\n",
        "      outs:\n",
        "        - ${item.output_path}\n",
        "\n",
        "  train:\n",
        "    cmd: python train.py --max-epochs 1\n",
        "    deps: \n",
        "      - sample_data/mnist_train_small.pkl\n",
        "    outs:\n",
        "      - model.ckpt\n",
        "\n",
        "  \n",
        "  test:\n",
        "    cmd: python test.py\n",
        "    deps:\n",
        "     - model.ckpt\n",
        "     - sample_data/mnist_test.pkl\n",
        "    metrics:\n",
        "      - metrics.json:\n",
        "          cache: false\n"
      ],
      "metadata": {
        "id": "QQVTo8wX3sOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc repro"
      ],
      "metadata": {
        "id": "wEFXKat_8lsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add dvc* *.py metrics.json\n",
        "!git commit -a -m \"Initial training\""
      ],
      "metadata": {
        "id": "k5YCg4e2OaC_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}